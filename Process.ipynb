{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API\n",
    "- Tensorflow Object Detection API는 TensorFlow를 이용해서 Object Detection 모델을 train하고 deploy하는 것을 쉽게 도와주는 오픈소스 프레임워크.\n",
    "- https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "- Tutorial: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom (Image) Data 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom (Image) Data Labeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전단계\n",
    "- 구글드라이브 연결\n",
    "- raw_data의 데이터압축파일을 VM local에 압축 푼다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection 2 API 설치\n",
    "1. clone \n",
    "    - `!git clone https://github.com/tensorflow/models.git`\n",
    "1. PYTHONPATH 환경설정에 models/research 추가  \n",
    "1. 필요 모듈 설치\n",
    "    - `!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk`\n",
    "    - `!pip install -qq Cython contextlib2 pillow lxml matplotlib pycocotools`\n",
    "1. proto 파일 컴파일\n",
    "    - models/research 경로로 이동\n",
    "        - `%cd models/research`\n",
    "    - `!protoc object_detection/protos/*.proto --python_out=.`\n",
    "1. setup.py 를 이용해 필요한 모듈 추가 설치\n",
    "    - setup.py를 현재 디렉토리로 카피\n",
    "        - `!cp object_detection/packages/tf2/setup.py . `\n",
    "    - 설치\n",
    "        - `!python -m pip install . `\n",
    "    - 설치 확인 - 아래 스크립트 실행시 오류 없이 실행되면 설치 잘 된 것임.\n",
    "        - `!python object_detection/builders/model_builder_tf2_test.py`\n",
    "1. 원래 디렉토리로 이동\n",
    "    - `%cd ../..`        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom data 학습 시키기\n",
    "\n",
    "## 다음 세가지 작업이 필요\n",
    "<span style='font-weight:bold;font-size:1.3em'>1. Label Map 파일 생성</span>\n",
    "- 분류 하고자 하는 object의 class와 그 class id 를 pbtxt text 파일로 작성\n",
    "- `models\\research\\object_detection\\data`\n",
    "\n",
    "```\n",
    "item {\n",
    "  id: 1\n",
    "  name: 'aeroplane'\n",
    "}\n",
    "\n",
    "item {\n",
    "  id: 2\n",
    "  name: 'bicycle'\n",
    "}\n",
    "...\n",
    "```\n",
    "\n",
    "<span style='font-weight:bold;font-size:1.3em'>2. pipeline.config</span>\n",
    "- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n",
    "- `models\\research\\object_detection\\samples\\configs`\n",
    "\n",
    "<span style='font-weight:bold;font-size:1.3em'>3. 학습/검증/테스트에 사용할 데이터셋을 TFRecord 로 구성</span>\n",
    "- 주요 데이터셋을 TFRecord로 생성하는 코드\n",
    "- `models\\research\\object_detection\\dataset_tools`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 설정파일 설정 및 데이터셋 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Map 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained Model Download\n",
    "- Tensorflow object detection API는 MS COCO 2017 dataset으로 미리 학습시킨 다양한 Object Detection 모델을 제공한다.\n",
    "- tf2 detection Model Zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "- SSD MobileNet V2 FPNLite 320x320 다운로드\n",
    "    - 성능은 떨어지지만 학습속도가 빠르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline.config 설정 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline.config  파일 개요\n",
    "- Model을 학습, 검증하기 위해 필요한 설정을 하는 파일\n",
    "- 구조\n",
    "    - https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/configuring_jobs.md\n",
    "    - **model**\n",
    "        - 사용하는 모델에 대한 설정\n",
    "        - class 개수\n",
    "        - 입력이미지 size\n",
    "        - anchor 설정\n",
    "    - **train_config**\n",
    "        - Train(학습)관련 설정\n",
    "        - batch_size\n",
    "            - 사용하는 GPU의 메모리 크기에 맞게 조절한다.\n",
    "        - image augmentation관련 설정 등\n",
    "        - optimizer관련 설정\n",
    "        - 학습에 사용할 weight 파일의 경로\n",
    "    - **train_input_reader**\n",
    "        - labelmap 파일 경로\n",
    "        - train tfrecord 파일 경로\n",
    "    - **eval_config**\n",
    "        - evaluation(평가)을 위해 사용하는 metric 설정\n",
    "    - **eval_input_config**\n",
    "        - labelmap 파일 경로\n",
    "        - evaluation tfreord 파일 경로\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain model의 pipeline.config 파일 카피\n",
    "- pretrained 모델의 압축을 풀면 pipeline.config 파일이 있다.\n",
    "- workspace\\model 로 copy 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pipeline.config 설정 변경\n",
    "- pipeline.config 내용 변경은 파일을 **직접 변경**할 수도 있고 **코드상에서 변경**할 수도 있다.\n",
    "\n",
    "### 필수 변경사항\n",
    "-  class개수 변경\n",
    "-  train 배치 사이즈 변경 - gpu 메모리 사양에 맞게 변경한다.\n",
    "-  pretrained model 경로 설정\n",
    "-  pretrained model이 어떤 종류의 모델인지 설정\n",
    "-  train 관련 변경\n",
    "    -  labelmap 파일 경로 설정\n",
    "    -  train 용 tfrecord 파일 경로 지정\n",
    "-  evaluation 관련 변경\n",
    "    -  labelmap 파일 경로 설정\n",
    "    -  evaluation 용 tfrecord 파일 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 학습\n",
    "- 다음 명령어를 실행한다.\n",
    "- 시간이 오래 걸리므로 terminal에서 실행한다.\n",
    "```\n",
    "python models/research/object_detection/model_main_tf2.py --model_dir=workspace/model/checkpoint --pipeline_config_path=workspace/model/pipeline.config --num_train_steps=3000\n",
    "```\n",
    "\n",
    "## 옵션\n",
    "- model_dir: 학습한 모델의 checkpoint 파일을 저장할 경로. (1000 step당 저장한다.)\n",
    "- pipeline_config_path: pipeline.config 파일 경로\n",
    "- num_train_steps: 학습할 step 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습한 모델 추출(export)\n",
    "- `models/research/object_detection/exporter_main_v2.py` 사용\n",
    "- 옵션\n",
    "    - `exporter_main_v2.py --helpshort || exporter_main_v2.py --helpfull`\n",
    "    - input_type : input node type\n",
    "        - image_tensor, encoded_image_string_tensor\n",
    "    - train_checkpoint: 학습된 checkpoint 파일이 저장된 경로(folder/directory)\n",
    "    - pipeline_config_path: pipeline.config 파일의 경로 (파일명 포함)\n",
    "    - output_directory: export된 모델을 저장할 경로.\n",
    "- 추출된 디렉토리 구조\n",
    "```bash\n",
    "output_dir\n",
    "├─ checkpoint/\n",
    "├─ save_model/\n",
    "└─ pipeline.config\n",
    "```\n",
    "    - checkpoint: custom data 학습한 checkpoint 파일들을 이 디렉토리로 복사한다.\n",
    "    - save_model: pipeline.config 설정에 맞춰 생성된 model\n",
    "    - pipeline.config: pipeline.config 설정파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference(추론)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용 함수,메소드\n",
    "-  ### tf.convert_to_tensor(array_like, dtype)\n",
    "    - array_like 를 Tensoflow Tensor 객체로 변환\n",
    "    - `tf.convert_to_tensor([[1,2],[3,4]])`\n",
    "- ### detection_model.preprocess(image 4차원 ndarray)\n",
    "    - 전달받은 이미지를 model의 input shape에 맞게 resizing 한다.\n",
    "    - 반환값: (resize된 image Tensor, 이미지의 shape) 을 tuple로 반환\n",
    "- ### detection_model.predict(image tensor, image_shape tensor)\n",
    "    - 추론/detection 메소드\n",
    "    - 이미지와 image shape을 받아서 detection한 결과를 딕셔너리로 반환한다.\n",
    "    - **반환 dictionary key**\n",
    "        - **preprocessed_inputs**:  입력 이미지 Tensor. preprocess()로 처리된 이미지. \n",
    "        - **feature_maps**: List. feature map 들을 반환\n",
    "        - **anchors**: 2D Tensor. normalize 된 anchor box들의 좌표를 반환. 2-D float tensor: \\[num_anchors, 4\\]\n",
    "        - **final_anchors**: 3D Tensor. batch 당 anchors. (anchors에 batch가 포함된 것). \\[batch_size, num_anchors, 4\\]\n",
    "        - **box_encodings**: 3D flost tensor. predict한 box들의 normalize된 좌표. \\[batch_size, num_anchors,box_code_dimension\\]\n",
    "        - **class_predictions_with_background**: 3D Tensor. 클래스 확률을 반환.(logit). \\[batch_size, num_anchors, num_classes+1]\\\n",
    "            - background 확률을 포함해서 num_classes+1개가 된다. (index 0: background)\n",
    "            \n",
    "- ### detection_model.postprocess(prediction_dict, shape)\n",
    "    - predict()가 예측한 결과에서 **Non-Maxinum Suppression**을 실행해서 최종 Detection 결과를 반환한다.\n",
    "        - predict()는 anchor별로 예측결과를 모아서 주고 post-process는 최종 결과를 추출해서 반환.\n",
    "    - **반환 dictionary key**\n",
    "        - **num_detections**: Detect한 개수 (bounding box 개수)\n",
    "        - **detection_boxes**: [batch, max_detections, 4]. 후처리한 detection box\n",
    "        - **detection_scores**: [batch, max_detections]. post-processed detection box들의 detection score들 (detection score는 box안에 물체가 있을 확률값 - confidence score).\n",
    "        - **detection_classes**: [batch, max_detections] tensor with classes for post-processed detection classes.\n",
    "        - **raw_detection_boxes**:[batch, total_detections, 4] Non-Max Suppression 하기 전의 감지된 box들\n",
    "        - **raw_detection_scores**: [batch, total_detections, num_classes_with_background]. raw detection box들의 class별 점수\n",
    "        - **detection_multiclass_scores**: [batch, max_detections, num_classes_with_background] post-processed이후 남은 bounding box 들의 class별 점수. LabelMap의 class에 background가 추가되어 계산된다.\n",
    "        - **detection_anchor_indices**: [batch, max_detections] post-processed 이후 나은 anchor box의 index들."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 새로운 이미지 Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
